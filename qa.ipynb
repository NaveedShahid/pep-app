{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import nltk\n",
    "# import tqdm\n",
    "# from transformers import pipeline\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# # from ner import get_ner, get_named_entities, name_match, name_match_single\n",
    "\n",
    "\n",
    "# model_name = \"AnonymousSub/news_pretrain_bert_FT_new_newsqa\"\n",
    "# qa_model = pipeline(model=model_name, tokenizer=model_name, task=\"question-answering\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Naveed-LFD\\anaconda3\\envs\\nlp\\lib\\site-packages\\thefuzz\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-27 16:57:53,021 loading file C:\\Users\\Naveed-LFD\\.flair\\models\\ner-english-ontonotes-large\\2da6c2cdd76e59113033adf670340bfd820f0301ae2e39204d67ba2dc276cc28.ec1bdb304b6c66111532c3b1fc6e522460ae73f1901848a4d0362cdf9760edb1\n"
     ]
    }
   ],
   "source": [
    "from qa import ask_question, get_multi_ner, check_pep, why_pep\n",
    "lst_of_text = \"Shehbaz and Hamza summoned in money laundering case. The Federal Investigation Agency or FIA filed a petition before Judicial Magistrate Kamran Zafar in which it said the statements of 26 accused people would be recorded in the case. The judicial magistrate remarked that this should happen in court.On the other hand, Shehbaz Sharif and Hamza Shahbaz did not appear. Shehbaz had left for Sialkot to attend a workers’ convention.On September 16, Shehbaz Sharif, Hamza Shahbaz and other people accused in the case appeared before the accountability court, while Shehbaz’s wife Nusrat joined the trial through a representative.The court summoned her through a representative to start indictment proceedings at the next hearing.Shehbaz and Hamza have already been indicted.Shehbaz Sharif told the court that Nusrat was out of the country for medical treatment.She will join the proceedings once her treatment is over and he requested the court to allow her to join the proceedings through a representative.NAB has accused Shehbaz Sharif of money laundering and owning more assets than his known sources of income. \\nThe evidence collected revealed that Shehbaz and his sons Hamza Shehbaz and Suleman Shahbaz and wife Nusrat Shehbaz had net assets of Rs14.8 million in 1998, according to the accountability bureau.Shehbaz in “connivance with his other family members/benamidars accumulated assets to the tune of Rs7,328 million till 2018”.The amount is “disproportionate to known sources of income and for which neither the accused nor his other family members/benamidars could reasonably account for.” Shehbaz’s lawyer had, however, argued that a reference has been filed and investigation completed, adding that all questionnaires mentioned by NAB have been answered too.\"\n",
    "# \"Six bankers record statements against Shehbaz, Hamza in money laundering case. Shehbaz Sharif and his son Hamza Shahbaz.The bankers have recorded their statement under section 164 of the Code of Criminal Procedure in an Rs25 billion money laundering case registered by the Federal Investigation Agency (FIA) against the father and son duo.According to sources, the FIA has presented a list of 26 bankers alleging that the Shehbaz and Hamza opened various bank accounts in the name of security guards, watchmen, clerks working in the Ramzan Sugar Mills.Special Judicial Magistrate Muhammad Kamran Zafar had summoned the witnesses to record their statements today. He had also summoned Shehbaz and Hamza to appear for the cross-examination but were a no show.The magistrate after recording statements of six bankers adjourned the proceedings of the case for September 23 to record statements of the rest of the 20 witnesses. \\nAmong the 26 witnesses to record statements against Shahbaz Sharif and Hamza Shahbaz include Maleeha Yousaf of HBL New Muslim Town branch Lahore, Iram Batool Hashmi of MCB Bahawalpur branch, Afzal Ghauri Bhatti of MCB Karim Block, Iqbal Town branch Lahore, Ishfaq Ahmad of MCB Faisalabad branch, Hamid Ali of MCB Mianwali branch, Tayyab Ali of MCB Jhang Road branch, Chiniot, Muhammad Atif Ameer of MCB Sargodha branch, Afzaal Ahmad of MCB Akbar Chowk branch Lahore, Asif Naeem of MCB Jamia Bad branch, Syed Tabbassum Raza Naqvi of MCB Jamia Bad branch, Ahmad Ali of MCB Jhang Road branch, Chiniot, Khurram Shahzad of MCB Chenab Nagar branch, Chiniot, Muhammad Rehman Sarwar of MCB Faisalabad, Fareeha Ijaz of MCB Ajmal House branch, Lahore, Naveed Wahab of UBL, Chiniot branch, Tanvir Hussain of Meezan Bank, Chiniot branch, Asif Iqbal of UBL Chenab Nagar branch, Chiniot, Farrukh Hussain of Meezan Bank of Adda branch, Sargodha, Ghulam Mustafa of Allied Bank main branch Chiniot, Nadeem Ahmad, Kotwali branch Faisalabad, Naseer Ahmad of Allied Bank Faisalabad, Riaz Hussain of Allied Bank, Chiniot branch, Muhammad Zubair of Meezan Bank Lalian branch, Chiniot, Shakeel Ahmad of UBL Sargodha Road branch, Chiniot and Muhammad Hashaam of Meezan Bank, Main branch, Chiniot. \\nIt may be relevant to mention here that following investigations into the sugar scam, FIA Lahore had on November 14, 2020, registered an FIR No 39/20 against Shahbaz Sharif, Hamza Shahbaz and Salman Shahbaz for their alleged involvement in Rs 25 billion money laundering which FIA has claimed was committed through various benami accounts.Salman Shahbaz is currently in the UK and did not join the investigations whereas Shahbaz Sharif and Hamza Shahbaz have appeared before the FIA investigators couple of times and are currently on pre-arrest bails\"]\n",
    "question = \"What is the name of person being accused?\"\n",
    "question_why = \"What is the reason <NAME> is being accused?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Naveed-LFD\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\pipelines\\question_answering.py:189: UserWarning: topk parameter is deprecated, use top_k instead\n",
      "  warnings.warn(\"topk parameter is deprecated, use top_k instead\", UserWarning)\n",
      "c:\\Users\\Naveed-LFD\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\tokenization_utils_base.py:707: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "c:\\Users\\Naveed-LFD\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\pipelines\\question_answering.py:300: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  for span_id in range(num_spans)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 4.763131437357515e-05, 'start': 319, 'end': 351, 'answer': 'Shehbaz Sharif and Hamza Shahbaz'}\n"
     ]
    }
   ],
   "source": [
    "results = ask_question(lst_of_text, question, topK=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['ner_results'] = results['answer'].astype(str).apply(get_multi_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['pep_match_results'] = results['ner_results'].apply(check_pep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32816\\752640274.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# results = df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresults_why\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhy_pep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion_why\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Naveed-LFD\\Desktop\\Adverse Media New\\qa.py\u001b[0m in \u001b[0;36mwhy_pep\u001b[1;34m(names, lst_of_text, question, topK)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqa_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlst_of_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtopK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtopK\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Naveed-LFD\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Naveed-LFD\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     return arrays_to_mgr(\n\u001b[1;32m--> 465\u001b[1;33m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m     )\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Naveed-LFD\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Naveed-LFD\\anaconda3\\envs\\nlp\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "# results = df\n",
    "results_why = why_pep(results.answer.tolist(), results['text'].tolist(), question_why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_why = pd.read_csv('results_why.csv',index_col=0)\n",
    "results_why = results_why.rename({\"text\":\"index\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pep_matches_top_1(list_of_matches):\n",
    "    answers={}\n",
    "    if type(list_of_matches)!=list:\n",
    "        list_of_matches = eval(list_of_matches)\n",
    "    for ans in list_of_matches:\n",
    "        name = list(ans.keys())[0]\n",
    "        pep_list = list(ans.values())\n",
    "        if not pep_list==[{}]:\n",
    "            pep_name = list(sorted(pep_list[0].items(), key=lambda x: x[1], reverse=True)[0])[0]\n",
    "            answers.update({name:pep_name})\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['pred_ans'] = results['pep_match_results'].apply(lambda x: pep_matches_top_1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spans_start(df):\n",
    "    if len(df)==1:\n",
    "        return df\n",
    "    start = df.start.unique()[0]\n",
    "    end = np.max(df.values)\n",
    "    return pd.DataFrame([{\"start\":start,\"end\":end}])\n",
    "\n",
    "def spans_end(df):\n",
    "    if len(df)==1:\n",
    "        return df\n",
    "    end = df.end.unique()[0]\n",
    "    start = np.min(df.values)\n",
    "    return pd.DataFrame([{\"start\":start,\"end\":end}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spanss(df):\n",
    "    df= df[['start','end']].groupby('start').apply(spans_start)\n",
    "    df_start=df.reset_index(drop=True)\n",
    "    df_end = df_start.groupby('end').apply(spans_end).reset_index(drop=True)\n",
    "    return df_end.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spans = results_why.groupby('index').apply(spanss).reset_index()\n",
    "df_merged = results.merge(df_spans,on='index', how='left', suffixes=('','_why'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.drop_duplicates(['start','end','start_why','end_why'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged[3:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tmp_fn(df):\n",
    "    # print(df)\n",
    "    df=df[1]\n",
    "    df = df.reset_index()\n",
    "    text = list(set(df['index'].tolist()))[0]\n",
    "    lst_ents=[]\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    doc = nlp(text)\n",
    "    options = {\"ents\": [\"PEP\",\"Reason\"], \"colors\":  {\"PEP\": \"red\", \"Reason\":\"yellow\"}}\n",
    "    # options = {\"ents\": [\"PEP\"], \"colors\":  {\"PEP\": \"red\"}}\n",
    "    for i, row in df.iterrows():\n",
    "        accuse_char = doc.char_span(row['start_why'], row['end_why'])\n",
    "        if row['pred_ans']=={}:\n",
    "            continue\n",
    "        for pep in row['pred_ans']:\n",
    "            who_char = re.search(pep, text).span()\n",
    "            who_char=doc.char_span(who_char[0], who_char[1])\n",
    "            span = Span(doc, who_char.start, who_char.end, \"PEP\")\n",
    "            reason = Span(doc, accuse_char.start, accuse_char.end, \"Reason\")\n",
    "            if span not in lst_ents:\n",
    "                lst_ents.extend([\n",
    "                    span,\n",
    "                ])\n",
    "            if reason not in lst_ents:\n",
    "                lst_ents.extend([\n",
    "                    reason,\n",
    "                ])\n",
    "    doc.ents = lst_ents\n",
    "        \n",
    "    return displacy.render(doc, style='ent',options=options) \n",
    "\n",
    "# return spans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Span\n",
    "\n",
    "for grp in df_merged.groupby('index'):\n",
    "    print(tmp_fn(grp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f\n",
    "    print(text)\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    doc = nlp(text, disable=['tagger','parser','ner'])\n",
    "\n",
    "    # doc.spans[\"ents\"] = [\n",
    "    #     Span(doc, 3, 6, \"ORG\"), \n",
    "    #     Span(doc, 5, 6, \"GPE\"),\n",
    "    # ]   \n",
    "    options = {\"ents\": [\"PEP\", \"Reason\"], \"colors\":  {\"PEP\": \"red\", \"Reason\":\"yellow\"}}\n",
    "\n",
    "    who_char = doc.char_span(sample['start'], sample['end'])\n",
    "    accuse_char = doc.char_span(sample_accuse['start'], sample_accuse['end'])\n",
    "\n",
    "    doc.ents =  [\n",
    "        Span(doc, who_char.start, who_char.end, \"PEP\"), \n",
    "        Span(doc, accuse_char.start, accuse_char.end, \"Reason\"), \n",
    "    ]   \n",
    "        \n",
    "    s=spacy.displacy.render(doc, style='ent',options=options) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a2332156e2d5f642ed3ad4388e4eebe758de39a02b8884b75663012fda81288"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
